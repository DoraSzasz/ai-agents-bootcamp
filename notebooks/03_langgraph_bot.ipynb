{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AI Agents Bootcamp - Day 3\n",
    "## Interactive Interview Bot with LangGraph\n",
    "\n",
    "**What you'll build:** A stateful, looping interview practice system that asks questions, analyzes your answers, gives feedback, and adapts.\n",
    "\n",
    "**Key concepts:**\n",
    "- LangGraph state machines\n",
    "- Conditional routing (loops!)\n",
    "- Typed state management\n",
    "- Production patterns\n",
    "\n",
    "**Time:** ~10 minutes setup, then practice as long as you want!\n",
    "\n",
    "---\n",
    "\n",
    "üìö **Full Series:** [Standout Systems on Substack](https://teodoracoach.substack.com/)  \n",
    "üíª **GitHub:** [ai-agents-bootcamp](https://github.com/DoraSzasz/ai-agents-bootcamp)  \n",
    "üéØ **Coaching:** [teodora.coach](https://teodora.coach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              INTERVIEW PRACTICE BOT                     ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                        ‚îÇ\n",
    "‚îÇ  GENERATE ‚îÄ‚îÄ‚ñ∂ ASK ‚îÄ‚îÄ‚ñ∂ ANALYZE ‚îÄ‚îÄ‚ñ∂ FEEDBACK            ‚îÇ\n",
    "‚îÇ  QUESTIONS   QUESTION  ANSWER      ‚îÇ                   ‚îÇ\n",
    "‚îÇ                 ‚ñ≤                   ‚îÇ                   ‚îÇ\n",
    "‚îÇ                 ‚îÇ                   ‚ñº                   ‚îÇ\n",
    "‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ CONTINUE? ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                   ‚îÇ\n",
    "‚îÇ                       (loop)        ‚îÇ                   ‚îÇ\n",
    "‚îÇ                                     ‚ñº                   ‚îÇ\n",
    "‚îÇ                                  WRAP UP ‚îÄ‚îÄ‚ñ∂ END       ‚îÇ\n",
    "‚îÇ                                                        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**This loop is impossible in CrewAI.** LangGraph makes it elegant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langgraph langchain-openai langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up API Key\n",
    "\n",
    "**Option A (Recommended):** Use Colab Secrets  \n",
    "**Option B:** Paste directly below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Try Colab secrets first\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ API key loaded from Colab Secrets\")\n",
    "except:\n",
    "    # Fallback: paste your key here\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"sk-your-key-here\"  # ‚Üê Replace!\n",
    "    print(\"‚ö†Ô∏è  Using hardcoded key - add to Colab Secrets for security\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ All libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configure Your Interview\n",
    "\n",
    "**üéØ CUSTOMIZE THIS for your actual interview!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üéØ CUSTOMIZE THESE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "COMPANY = \"Anthropic\"              # Your target company\n",
    "POSITION = \"Senior ML Engineer\"    # The role\n",
    "DIFFICULTY = \"medium\"              # easy, medium, hard\n",
    "\n",
    "print(f\"üéØ Preparing for: {POSITION} at {COMPANY}\")\n",
    "print(f\"üìä Difficulty: {DIFFICULTY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define State (The Brain)\n",
    "\n",
    "This is THE critical LangGraph concept. State is:\n",
    "- **Typed** (catches bugs early)\n",
    "- **Shared** (all nodes read/write)\n",
    "- **Persistent** (can save/resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(TypedDict):\n",
    "    \"\"\"Everything the bot knows and remembers.\"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    company: str\n",
    "    position: str\n",
    "    difficulty: str\n",
    "    \n",
    "    # Questions\n",
    "    questions: List[str]\n",
    "    current_index: int\n",
    "    \n",
    "    # Conversation (Annotated = auto-append)\n",
    "    exchanges: Annotated[List[dict], operator.add]\n",
    "    \n",
    "    # Performance\n",
    "    scores: List[int]\n",
    "    weak_areas: List[str]\n",
    "    \n",
    "    # Flow control\n",
    "    user_wants_continue: bool\n",
    "    session_complete: bool\n",
    "\n",
    "print(\"‚úÖ State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build the Nodes\n",
    "\n",
    "Each node is a function: `state in ‚Üí updated state out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# NODE 1: GENERATE QUESTIONS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def generate_questions(state: InterviewState) -> dict:\n",
    "    \"\"\"Generate tailored interview questions.\"\"\"\n",
    "    \n",
    "    print(\"\\nüéØ Generating questions...\")\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"You are a senior interviewer at {state['company']}.\n",
    "        Generate exactly 5 interview questions for a {state['position']} role.\n",
    "        Difficulty: {state['difficulty']}\n",
    "        \n",
    "        Mix: 2 technical, 2 behavioral, 1 scenario.\n",
    "        Return ONLY numbered questions 1-5.\"\"\"),\n",
    "        HumanMessage(content=\"Generate questions now.\")\n",
    "    ])\n",
    "    \n",
    "    # Parse questions\n",
    "    lines = response.content.strip().split('\\n')\n",
    "    questions = [l.strip() for l in lines if l.strip() and l[0].isdigit()]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(questions)} questions\\n\")\n",
    "    for q in questions:\n",
    "        print(f\"   {q[:65]}...\" if len(q) > 65 else f\"   {q}\")\n",
    "    \n",
    "    return {\n",
    "        \"questions\": questions[:5],\n",
    "        \"current_index\": 0,\n",
    "        \"exchanges\": [],\n",
    "        \"scores\": [],\n",
    "        \"weak_areas\": []\n",
    "    }\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# NODE 2: ASK QUESTION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def ask_question(state: InterviewState) -> dict:\n",
    "    \"\"\"Present question and collect answer.\"\"\"\n",
    "    \n",
    "    idx = state[\"current_index\"]\n",
    "    question = state[\"questions\"][idx]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 55)\n",
    "    print(f\"üìù QUESTION {idx + 1} of {len(state['questions'])}\")\n",
    "    print(\"=\" * 55)\n",
    "    print(f\"\\nüé§ {question}\\n\")\n",
    "    \n",
    "    # Get answer\n",
    "    user_answer = input(\"Your answer: \")\n",
    "    \n",
    "    exchange = {\n",
    "        \"question_num\": idx + 1,\n",
    "        \"question\": question,\n",
    "        \"answer\": user_answer\n",
    "    }\n",
    "    \n",
    "    return {\"exchanges\": [exchange]}\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# NODE 3: ANALYZE ANSWER\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def analyze_answer(state: InterviewState) -> dict:\n",
    "    \"\"\"Score and analyze the answer.\"\"\"\n",
    "    \n",
    "    last = state[\"exchanges\"][-1]\n",
    "    print(\"\\n‚è≥ Analyzing...\")\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"\"\"Analyze this interview answer.\n",
    "        \n",
    "        Format EXACTLY:\n",
    "        SCORE: [1-10]\n",
    "        STRENGTHS: [what was good]\n",
    "        IMPROVEMENTS: [what to improve]\n",
    "        PRO TIP: [one tip]\n",
    "        WEAK_AREA: [skill to work on, or \"none\" if score >= 7]\"\"\"),\n",
    "        HumanMessage(content=f\"Q: {last['question']}\\nA: {last['answer']}\")\n",
    "    ])\n",
    "    \n",
    "    # Parse score\n",
    "    content = response.content\n",
    "    score = 5\n",
    "    weak_area = None\n",
    "    \n",
    "    for line in content.split('\\n'):\n",
    "        if line.startswith('SCORE:'):\n",
    "            try:\n",
    "                score = int(line.split(':')[1].strip().split('/')[0])\n",
    "            except: pass\n",
    "        elif line.startswith('WEAK_AREA:'):\n",
    "            area = line.split(':')[1].strip()\n",
    "            if area.lower() != 'none':\n",
    "                weak_area = area\n",
    "    \n",
    "    state[\"exchanges\"][-1][\"score\"] = score\n",
    "    state[\"exchanges\"][-1][\"feedback\"] = content\n",
    "    \n",
    "    result = {\"scores\": state.get(\"scores\", []) + [score]}\n",
    "    if weak_area:\n",
    "        result[\"weak_areas\"] = state.get(\"weak_areas\", []) + [weak_area]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# NODE 4: GIVE FEEDBACK\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def give_feedback(state: InterviewState) -> dict:\n",
    "    \"\"\"Show feedback and ask to continue.\"\"\"\n",
    "    \n",
    "    last = state[\"exchanges\"][-1]\n",
    "    score = last.get(\"score\", 5)\n",
    "    feedback = last.get(\"feedback\", \"\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 55)\n",
    "    print(\"üìä FEEDBACK\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    bar = \"‚ñà\" * score + \"‚ñë\" * (10 - score)\n",
    "    emoji = \"üåü\" if score >= 8 else \"‚úÖ\" if score >= 6 else \"üîß\"\n",
    "    print(f\"\\n{emoji} Score: [{bar}] {score}/10\\n\")\n",
    "    print(feedback)\n",
    "    \n",
    "    new_index = state[\"current_index\"] + 1\n",
    "    remaining = len(state[\"questions\"]) - new_index\n",
    "    \n",
    "    if remaining > 0:\n",
    "        cont = input(f\"\\n‚û°Ô∏è  Continue? ({remaining} left) (yes/no): \").lower()\n",
    "        wants_continue = cont in ['yes', 'y', '']\n",
    "    else:\n",
    "        print(\"\\nüìù All questions done!\")\n",
    "        wants_continue = False\n",
    "    \n",
    "    return {\n",
    "        \"current_index\": new_index,\n",
    "        \"user_wants_continue\": wants_continue\n",
    "    }\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# NODE 5: WRAP UP\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def wrap_up(state: InterviewState) -> dict:\n",
    "    \"\"\"Final summary and advice.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 55)\n",
    "    print(\"üéì SESSION COMPLETE\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    scores = state.get(\"scores\", [])\n",
    "    if scores:\n",
    "        avg = sum(scores) / len(scores)\n",
    "        print(f\"\\nüìä Results:\")\n",
    "        print(f\"   ‚Ä¢ Questions: {len(scores)}\")\n",
    "        print(f\"   ‚Ä¢ Average: {avg:.1f}/10\")\n",
    "        print(f\"   ‚Ä¢ Best: {max(scores)}/10\")\n",
    "    \n",
    "    if state.get(\"weak_areas\"):\n",
    "        print(f\"\\nüéØ Practice these:\")\n",
    "        for area in set(state[\"weak_areas\"]):\n",
    "            print(f\"   ‚Ä¢ {area}\")\n",
    "    \n",
    "    # Final advice\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"\"\"Give 2 specific tips based on this session.\n",
    "        Keep under 75 words. Be encouraging.\"\"\"),\n",
    "        HumanMessage(content=f\"Scores: {scores}, Weak areas: {state.get('weak_areas', [])}\")\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nüí° Coach's Notes:\\n{response.content}\")\n",
    "    \n",
    "    return {\"session_complete\": True}\n",
    "\n",
    "\n",
    "print(\"‚úÖ All 5 nodes defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: The Router (Decision Logic)\n",
    "\n",
    "This is what makes LangGraph special: **conditional edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: InterviewState) -> Literal[\"ask_question\", \"wrap_up\"]:\n",
    "    \"\"\"Decide: loop back or exit?\"\"\"\n",
    "    \n",
    "    # User said stop\n",
    "    if not state.get(\"user_wants_continue\", True):\n",
    "        return \"wrap_up\"\n",
    "    \n",
    "    # All questions done\n",
    "    if state[\"current_index\"] >= len(state[\"questions\"]):\n",
    "        return \"wrap_up\"\n",
    "    \n",
    "    # Continue the loop!\n",
    "    return \"ask_question\"\n",
    "\n",
    "print(\"‚úÖ Router defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Assemble the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(InterviewState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate_questions\", generate_questions)\n",
    "workflow.add_node(\"ask_question\", ask_question)\n",
    "workflow.add_node(\"analyze_answer\", analyze_answer)\n",
    "workflow.add_node(\"give_feedback\", give_feedback)\n",
    "workflow.add_node(\"wrap_up\", wrap_up)\n",
    "\n",
    "# Set entry\n",
    "workflow.set_entry_point(\"generate_questions\")\n",
    "\n",
    "# Linear edges\n",
    "workflow.add_edge(\"generate_questions\", \"ask_question\")\n",
    "workflow.add_edge(\"ask_question\", \"analyze_answer\")\n",
    "workflow.add_edge(\"analyze_answer\", \"give_feedback\")\n",
    "\n",
    "# THE LOOP - conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"give_feedback\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"ask_question\": \"ask_question\",  # Loop!\n",
    "        \"wrap_up\": \"wrap_up\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"wrap_up\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Graph compiled and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize the Graph (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the flow (requires graphviz)\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(\"Graph visualization requires: pip install grandalf\")\n",
    "    print(\"\\nFlow: generate ‚Üí ask ‚Üí analyze ‚Üí feedback ‚Üí [loop or wrap_up] ‚Üí END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Run Your Interview Bot! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"company\": COMPANY,\n",
    "    \"position\": POSITION,\n",
    "    \"difficulty\": DIFFICULTY,\n",
    "    \"questions\": [],\n",
    "    \"current_index\": 0,\n",
    "    \"exchanges\": [],\n",
    "    \"scores\": [],\n",
    "    \"weak_areas\": [],\n",
    "    \"user_wants_continue\": True,\n",
    "    \"session_complete\": False\n",
    "}\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(\"ü§ñ INTERVIEW PRACTICE BOT\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"üìç Company: {COMPANY}\")\n",
    "print(f\"üíº Position: {POSITION}\")\n",
    "print(f\"üìä Difficulty: {DIFFICULTY}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Run it!\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n‚úÖ Session complete! Good luck! üçÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Review Your Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Build summary\n",
    "summary = f\"\"\"## üìã Session Summary\n",
    "\n",
    "**Company:** {result['company']}  \n",
    "**Position:** {result['position']}  \n",
    "**Questions Completed:** {len(result['scores'])}\n",
    "\n",
    "### Scores\n",
    "\"\"\"\n",
    "\n",
    "for i, (ex, score) in enumerate(zip(result['exchanges'], result['scores']), 1):\n",
    "    bar = \"‚ñà\" * score + \"‚ñë\" * (10 - score)\n",
    "    summary += f\"- Q{i}: [{bar}] {score}/10\\n\"\n",
    "\n",
    "if result['weak_areas']:\n",
    "    summary += \"\\n### Areas to Practice\\n\"\n",
    "    for area in set(result['weak_areas']):\n",
    "        summary += f\"- {area}\\n\"\n",
    "\n",
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Experiments to Try\n",
    "\n",
    "**Easy:**\n",
    "- Change company/position to your actual interview\n",
    "- Try different difficulty levels\n",
    "\n",
    "**Medium:**\n",
    "- Add a \"hint\" option before answering\n",
    "- Track time spent per question\n",
    "- Save results to a file\n",
    "\n",
    "**Advanced:**\n",
    "- Add voice input (speech-to-text)\n",
    "- Make questions adaptive (harder if doing well)\n",
    "- Add a \"mock interviewer\" that asks follow-ups\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ The Complete Journey\n",
    "\n",
    "| Day | What You Learned | Pattern |\n",
    "|-----|-----------------|--------|\n",
    "| 1 | Agent fundamentals | Single agent, basic loop |\n",
    "| 2 | Multi-agent systems | CrewAI, task chaining |\n",
    "| **3** | **Production patterns** | **LangGraph, state, loops** |\n",
    "\n",
    "**You now have the complete toolkit for building real AI systems.**\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Keep Learning\n",
    "\n",
    "**Subscribe:** [Standout Systems](https://teodoracoach.substack.com/)  \n",
    "**GitHub:** [ai-agents-bootcamp](https://github.com/DoraSzasz/ai-agents-bootcamp)  \n",
    "**Coaching:** [teodora.coach](https://teodora.coach)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
